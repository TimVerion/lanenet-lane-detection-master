# lanenet论文翻译

**Towards End-to-End Lane Detection an Instance Segmentation Approach**

本文作者Davy Neevn是鲁汶大学博士研究生，鲁汶大学是比利时久负盛名的最高学府，欧洲历史最悠久且最受人尊敬的大学之一，也是享誉全球的世界级顶尖研究型大学。Davy Neevn近几年一直在从事语义分割、场景理解、实例分割等课题的研究。

LaneNet是一个端到端的车道线检测算法，可以解决车道线数目变化（pixel embedding）以及车道视角变化(逆向透视矩阵)的问题。

**摘要：**当今很多车都带有辅助驾驶员的驾驶的功能，比如车道保持功能。该功能能使车辆保持在车道间的适当位置，这个功能对于有潜在车道偏离或者自动驾驶中的轨迹规划和决策都至关重要。传统的车道检测方法依赖于高度定义化，`手工特征提取和启发式方法`，通常是需要后处理技术，而这往往会使得计算量大，不利于道路场景多变下的应用扩展。

最近越来越多的方法是借助深度学习建模，为像素级的车道分割做训练，即使当在大的感受野中并无车道标记的存在。尽管这类方法有他们的优势，但他们`受限于检测一个预训练的固定数量的车道线`（比如本车道）问题，且无法处理车道变化。

 本文，我们突破了前面提到的限制，`将车道检测问题转为实例分割问题`，从而每个车道线各自形成一个实例，这样就能够实现端到端的训练了。在分割车道线用于拟合车道之前，我们进一步提出采用一个`已学习好的透视变换`，在图像上做这种调整，与固定的鸟瞰图做对比。通过这么做，我们`确保在道路平面变化下的车道线拟合的鲁棒性`，不同于现有依赖于固定的且预先定义的透视变换矩阵的方法。总结就是，我们提出了一种快速车道检测的算法，`运行帧率达50fps且能够处理多数车道和车道变换`。本算法在tuSimple(图森)数据集中验证过且取得较优的结果。

**车道检测的发展：**

目前，无论是在学术还是工业层面，自动驾驶都是计算机视觉和机器人技术研究的主要焦点。不论何种方案，都需要使用各种传感器和控制模块，感知汽车周围的环境。基于摄像头的车道检测是环境感知的重要方法，它可以让车辆在车道内正确定位，同时它对后续的车道偏离或轨迹规划也至关重要。因此，准确的基于摄像头的车道检测是实现完全自动驾驶的关键推动因素。

较为常见的手工特征提取是基于颜色的，结构的，bar filter(条形过滤器), ridge feature(脊线特征)等，结合hough 变换和粒子滤波或Kalman滤波(卡尔曼滤波器)。当识别出车道线之后，利用后处理技术过滤掉误检和成组分割在一起的情况以得到最终车道线。通常，这些传统方法很容易由于道路场景变化而导致鲁棒性问题。

最近的研究有人用深度神经网络取代手工标记，通过构建一定量学习密集的特征检测器进行预测，即像素级的车道分。下面是当前深度网络相关研究：

- Gopalan等人用像素层次结构特征描述子来做上下文信息建模并且用增强算法来选择相关上下文信息特征做车道标记检测。
- Kim and Lee 将CNN和[RANSAC](https://blog.csdn.net/lwx309025167/article/details/80590549)(随机采样一致性) 算法结合用边缘图像来检测车道，他们用CNN主要是为了图像增强，而且只有在道路场景复杂情况下，例如路边树，栅栏或十字路口效果较好。
- Huval等人提出使用现有的CNN模型能用于高速自动驾驶，得到端到端的CNN能够用于车道检测与分类。
- He等人介绍了一种双视觉CNN网络-DVCNN，利用前视和俯视图像可排除误检和去除非车道结构的目标。
- Li等人利用多目标深度卷积网络用于寻找车道的几何结构属性（如位置，方向）并结合RNN来检测车道线。
- Lee等提出多任务网络能同时检测和识别车道和道路标记，即便在不好天气和低光照条件。

**上述深度网络的方法的共性问题：**

产生的二值化车道线分割图仍需要分离到不同的车道实例中。

为处理这个问题一些方法采用后处理来解决，主要是用启发式的方法比如几何特性，但启发式方法计算量大且受限于场景变化鲁棒性问题。

另一条思路是将`车道检测问题转为多类别分割问题`，每条车道属于一类，这样能实现端到端的训练出分类好的二进制图。但该方法受限于只能检测预先定义的，固定数量的车道线。此外，由于每个车道都有一个指定的类别，所以它`无法处理车道的变化`。

**论文思路：**

受深度网络在语义分割和实例分割任务等成功的启发，将车道检测问题转为实例分割问题，`每个车道线形成独立的实例，但都属于车道线这个类别`。我们设计了一个带分支结构的多任务网络，如车道实例分割，由一个`车道分割分支`和一个`车道嵌入分支`构成能够实现端到端训练。

车道分割分支输出两类：背景或车道线；

车道嵌入分支进一步将分段的车道像素分解成不同的车道实例；

通过将车道检测问题分解为上述两个任务，`我们可以充分利用车道分割分支的功能`，而不必为不同的车道分配不同的类别。相反，`使用聚类损失函数训练的车道嵌入分支将车道ID分配给来自车道分割分支的每个像素`，同时忽略背景像素。通过这样做，我们减轻了车道变化的问题，并且我们可以处理可变数量的车道。论文模型的主框架如下图：

![network_architecture](H:\real_work\LanNet_车道检测\lanenet-lane-detection-master\README\network_architecture.png)

> LaneNet结构。分割分支（底部）被训练以产生二进制车道。嵌入分支（TOP）生成每个车道像素的n维嵌入，使得来自同一车道的嵌入是紧密的，而来自不同车道的嵌入是相距甚远的。为了简单起见，我们展示了每个像素的二维嵌入，它被可视化为XY网格中的颜色映射（所有像素）和点（仅是车道像素）。在利用分割分支的二值分割图遮蔽背景像素之后，将车道嵌入（蓝点）聚集在一起并分配给它们的聚类中心（红点）。

当得到车道实例（即知道哪些像素属于哪条车道）后，就需要对每条线做参数描述,曲线拟合算法作为这个参数描述，流行的拟合模型有三阶多项式(本文使用)，样条曲线，回旋曲线(布卢姆曲线)。`为了提高拟合质量且保持计算效率，通常将图像转到鸟瞰图后做拟合`("bird eye")。`最后再逆变换到原图即可`。通常变换矩阵是在单个图像上计算的并保持固定,但是如果地平面变化较大（例如通过倾斜上坡）,则该固定变换不再有效。

为了解决道路平面变动的影响，我们在对曲线进行拟合之前对图像应用透视变换，然后`训练一个神经网络来输出变换系数`。神经网络将图像作为输入，并针对车道配合问题量身定制一个损失函数进行优化。

![2019-11-27_212313](H:\real_work\LanNet_车道检测\lanenet-lane-detection-master\README\2019-11-27_212313.jpg)

> 上图概述：给定一个输入图像，LaneNet输出一个lane实例分割图，用lane id标记每个lane像素。
>
> 然后使用变换矩阵对lane像素进行变换，H-Net根据输入图像学习输出一个透视变换矩阵。
>
> 对每个车道进行三阶多项式拟合，并将车道重新投影到图像上。

**基于学习方法的投影方法H-Net**

- 将输入的RGB图像作为输入，使用LaneNet得到输出的实例分割结果，然后将车道线像素使用H-Net输出得到的透视变换矩阵进行变换，对变换后的车道线像素在变化后的空间中进行拟合，再将拟合结果经过逆投影，最终得到原始视野中的车道线拟合结果。
- H-Net将RGB作为输入，输出为基于该图像的透视变换系数矩阵，优化目标为车道线拟合效果

![2019-11-28_113228](H:\real_work\LanNet_车道检测\lanenet-lane-detection-master\README\2019-11-28_113228.jpg)

> 视觉效果。 第一行：ground-truth 车道点。 中间行：LaneNet输出。 底行：最后经过lane fitting的车道线预测。

#### **LaneNet的实现：**

***️⃣网络结构**

LaneNet是基于[ENet](https://arxiv.org/abs/1606.02147) 的encoder-decoder模型，如图5所示，[ENet](https://blog.csdn.net/zijinxuxu/article/details/67638290)由5个stage组成，其中stage2和stage3基本相同，stage1,2,3属于encoder，stage4,5属于decoder。

如上图所示，在LaneNet 中，语义分割和实例分割两个任务共享 stage1 和 stage2，并将 stage3 和后面的 decoder 层作为各自的分支(branch)进行训练；其中，语义分割分支(branch)的输出 shape 为W\*H\*2，实例分割分支(branch)的输出 shape 为W\*H\*N，W,H分别为原图宽和高，N 为 embedding vector 的维度()；两个分支的loss权重相同都是0.5。

**🅰️二值化分割**

上图中的下面那个分支就是用于训练输出得到一个二值化的分割图，白色代表车道线，黑色代表背景。为了构建GT分割图，我们将每条车道线对应的像素连成线，这么做的好处是即使车道线被遮挡了，网络仍能预测车道位置。给分割网络用标准的交叉熵损失函数做训练的。由于目标类别是2类(车道/背景)高度不平衡(就是背景较车道线的像素多太多),这里应用 [bounded inverse class weighting](https://arxiv.org/abs/1606.02147)(有界逆类加权)缓解这一问题。
$$
W_{class} = \frac{1}{ln(c+p(class))}
$$
其中，p 为对应类别在总体样本中出现的概率，c 是超参数（ENet论文中是1.02）。

```
# 在代码lanenet_model/lanenet_merge_model.py,100行有体现
```

**🅱️实例分割**

当分割分支识别得到车道后，为了区分车道线上的像素属于哪条车道，我们训练了一个车道嵌入分支网络（上图上面那个网络）。embedding_branch 为每个像素初始化一个 embedding 向量，并且在设计 loss 时，使属同一条车道线的像素向量距离尽可能小，属不同车道线的像素向量距离尽可能大。

这部分的 loss 函数是由三部分组成：方差 loss(Lvar) 和距离 loss(Ldist)和正则：

![2019-11-28_150852](F:\pics\lannet\2019-11-28_150852.jpg)

 其中，C 是车道线数量训练的时候按照标签的车道数目给定，Nc是属同一条车道线的像素点数量，μc 是车道线的均值向量，xi 是像素向量（pixel embedding)，[x]+等价于max(0,x)。注意这里先执行 + 操作，再执行 2(平方)操作。

该 loss 函数源自于论文 [《Semantic Instance Segmentation with a Discriminative loss function》](https://arxiv.org/abs/1708.02551v1.pdf) 

```
# 详细见lanenet_discriminative_loss.py
```

![2019-11-28_151642](H:\real_work\LanNet_车道检测\lanenet-lane-detection-master\README\2019-11-28_151642.jpg)

> 当车道线均值向量 μ_c 超过阈值  δv 的时候就将像素向量往均值方向拉
>
> 当不同车道的均值向量距离太近了小于δd时，往远处推
>
> 终止的条件是,各车道均值向量距离(即各车道线间间距)>δd,每条车道线中包含的像素向量离该车道线均值向量<δv。

LaneNet只在两个分支之间共享前两个阶段(1和2)，而将ENet编码器的第三阶段和完整的ENet解码器作为每个独立分支的主干。分割分支的最后一层输出单通道图像(二值分割)，而嵌入分支的最后一层输出N通道图像，嵌入维数为N。如图2所示。每个分支的损失项都是等权的，并通过网络反向传播。

**🆎聚类**

注意，聚类可以看做是个后处理，上一步里 embedding_branch 已经为聚类提供好的特征向量了，利用这些特征向量我们可以利用任意聚类算法来完成实例分割的目标。

为了方便聚类，论文中设定 **δd>6δv**.

在进行聚类时，首先使用 [mean shift ](https://www.cnblogs.com/xfzhang/p/7261172.html)(DBSCAN)聚类，使得簇中心沿着密度上升的方向移动，防止将离群点选入相同的簇中；之后对像素向量进行划分：以簇中心为圆心，以 2δv 为半径，选取圆中所有的像素归为同一车道线。重复该步骤，直到将所有的车道线像素分配给对应的车道。

**⏰H-Net**

 LaneNet的输出是每条车道线的像素集合，还需要根据这些像素点回归出一条车道线。原因是存储车道线像素点占据内存远大于方程式,二是拟合出的方程式是一条光滑曲线，有利于滤除噪声点。

![2019-11-28_174153](H:\real_work\LanNet_车道检测\lanenet-lane-detection-master\README\2019-11-28_174153.jpg)

传统的做法是将图片投影到 bird’s-eye view 中，然后使用 2 阶或者 3 阶多项式进行拟合。在这种方法中，变换矩阵 H 只被计算一次，所有的图片使用的是相同的变换矩阵，这会导致地平面（山地，丘陵）变化下的误差。

 为了解决这个问题，论文训练了一个可以预测[变换矩阵](https://www.jianshu.com/p/b49f9dbb26ea) H 的神经网络 H-Net，网络的输入是图片，输出是变换矩阵 H：
$$
H = \begin{bmatrix}a & b & c \\ 0& d & e\\ 0&f&1\end{bmatrix}
$$

> 通过置 0 对转置矩阵进行约束，即水平线在变换下保持水平。（即坐标 y 的变换不受坐标 x 的影响）

由上式可以看出，转置矩阵 H 只有6个参数，因此H-Net的输出是一个 6 维的向量。H-Net 由 6 层普通卷积网络和一层全连接网络构成，其网络结构如图所示：

![2019-11-28_165531](H:\real_work\LanNet_车道检测\lanenet-lane-detection-master\README\2019-11-28_165531.jpg)

**✈️ 曲线拟合**

曲线拟合的过程就是通过坐标 y 去重新预测坐标 x 的过程：

- 对于包含 N 个像素点的车道线，每个像素点 ${pi=[x_i,y_i,1]^T∈P }$首先使用 H-Net 的预测输出 H 对其进行坐标变换：

$$
P^{'} = HP
$$

- 通过这些投影点拟合出一条曲线:

$$
{f(y^{'}) = \alpha y^{'2}+\beta y^{'}+\gamma}
$$

- 随后使用最小二乘法对三阶多项式的参数进行拟合:
  $$
  \space \space w = (Y^TY)^{-1}Y^Tx^{'}
  $$

  $$
  Y = \begin{bmatrix}y_1^{'2} & y_1^{'} & 1 \\ .& . & .\\ y_N^{'2}&y_N^{'}&1\end{bmatrix}\\
  $$

$$
\space w = [\alpha,\beta,\gamma]^T,x^{'}=[x_1^{'},x_2^{'},..,x_N^{'}]^T\\
$$

- 根据拟合出的参数 w=[α,β,γ]T 预测出 ${x_i^{'*}}$
  $$
  x_i^{'*} =αy^{'2}+βy′+γ
  $$

- 最后将 ${p_i^{'*} = [x_i^{'*},y_i^{'},1]^T}$投影回去：

$$
p_i^*=H^{-1}p_i^{'*}
$$



- 损失函数

$$
Loss=\frac{1}{N}\sum^{N}_{i=1}(x_i^{*}−x_i)^2
$$

**🗡实验参数**

```
# LaneNet
Dataset : Tusimple
Embedding dimension = 4
δ_v=0.5
δ_d=3
Image size = 512*256
Adam optimizer
Learning rate = 5e-4
Batch size = 8

# H-Net
Dataset : Tusimple
3rd-orderpolynomial
Image size =128*64
Adam optimizer
Learning rate = 5e-5
Batch size = 10
```

**🎯评价指标**

语义分割部分

用的是TuSimple的车道线数据集，3626张训练图像和2782张测试图像，采集自较好和稍好的气候情况。包含白天不同时刻2,3,4车道或较多的高速道路。每张图都提供了该图前19帧图像（不过这19帧是未标注的），标注的图像是json格式的。指示在许多离散的y坐标上对应的x位置。每张图包含当前车道（左右车道）的车道线标准信息（共计4条线），测试集也如此，当改变车道时，会出现第5条车道线。
准确性的定义是每张图gt点数中正确点所占的比例。

精度计算为每幅图像的平均正确点数:
$$
acc = \sum_{im}\frac{C_{im}}{S_{im}}
$$
用Cim表示正确点的个数，用Sim表示地面真值点的个数。所谓预测正确的点是那些与gt点距离小于一定阈值的就认为预测准确。作者还给出False positive和false negative的定义作为模型好坏的评测标准。
$$
FP = \frac{F_{pred}}{N_{pred}} \space \space \space FN = \frac{M_{pred}}{N_{gt}}
$$
${F_{pred}}$为预测错误车道数，${N_{pred}}$为预测车道数，${M_{pred}}$为未预测到的地面真车道数，${N_{gt}}$为所有地面真车道数。

[第三方](https://github.com/stesha2016/lanenet-enet-hnet)

${accuracy=\frac{2}{1/recall+1/precision}}$



${recall=\frac{|P1∩G1|}{|G1|}}$ # 统计GT中车道线分对的概率



${precision=\frac{|P0∩G0|}{|G0|}}$ # 统计GT中背景分对的概率



设定 G1代表 GT二值图里像素值为 1 部分的集合，P1P1 表示检测结果为 1 的集合。

 **官方**

${recall=\frac{|P1∩G1|}{|G1|}}$# 统计GT中车道线分对的概率



${fp=\frac{|P1|−|P1∩G1|}{|P1|}}$ # 统计Pre中的车道线误检率



${fn=\frac{|G1|−|P1∩G1|}{|G1|}}$ # 统计GT车道线中漏检率



**👽 相关实验**

1. 替换 backbone 为 mobilenet_v2
2. 调整 embedding dim
3. 预处理方式调整
4. 上采样方式替换
5. 学习率衰减方式
6. 反卷积卷积核尺寸调整

`作者最后的结论就是用H-Net比用固定的转换矩阵要好，用3阶多项式拟合要比2阶好，用了透视变换比不用好`

总的来说贡献点有两个：（1）分支的多任务体系结构，车道分割分支输出车道和背景，而车道嵌入分支进一步将分段的车道像素分解成不同的车道实例。（2）给定输入图像的网络估计透视变换的参数，透视变换允许车道拟合对路面变化具有鲁棒性。

参考:

https://mp.weixin.qq.com/s?__biz=MzUxNjcxMjQxNg==&mid=2247484611&idx=1&sn=273851087cc6ea2cf92fdb7e3658f8b5&chksm=f9a2764cced5ff5a3673cd7d18674725c6e4aa6c6db59952b062082a789262e7e60377dc0755&mpshare=1&scene=1&srcid=0612oBg7J15vjYAsvgOwV232&pass_ticket=SM3Zjd8RlcWvcbAGAu3F2ZnAVZItCVv3DON%2BVf82wNQtwq3ewMkXeUZQnbAcUviF#rd

https://www.cnblogs.com/xuanyuyt/p/11523192.html